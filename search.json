[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kelvin Boateng",
    "section": "",
    "text": "About me\nBackground\nA Geomatic Engineer with extensive experience in GIS, land surveying, and environmental management, focused on applying precise spatial data solutions to mining, construction, and infrastructure projects. I have developed practical expertise in site layout, topographic mapping, road profiling, land demarcation, and generating high-resolution orthophotos using advanced surveying instruments and drone technology. My professional experience spans roles as a Geomatic Engineer, Assistant Surveyor, and Survey Assistant, where I was responsible for setting out structural equipment, verifying excavation levels, establishing control points, and producing accurate survey documentation to guide engineering and environmental decision-making. Through rigorous training and hands-on practice in spatial data analysis, remote sensing, geospatial modelling, GIS-based mapping, Google Earth Engine, Python, and R, I have honed the ability to integrate field data with analytical tools effectively. This combination of field experience and technical expertise enables the delivery of reliable, actionable spatial information that informs sustainable land use, resource planning, and environmental management."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Education\nMaster of Geomatics for Environmental Management, Jul 2025 – Apr 2026 (expected completion)\nUniversity of British Columbia\nBachelor of Science, Geomatic Engineering, Oct 2018 – Sept 2022\nUniversity of Mines and Technology, (UMaT)\n\n\nTechnical Skills\n• GIS & Remote Sensing: QGIS, ArcGIS, Agisoft Metashape, Google Earth Engine\n• Surveying Tools: AutoCAD Civil 3D, Topcon Tools, Magnet Tools, MapInfo\n• Programming & Data Science: Python (Intermediate), R (Intermediate), Java (OpenStreetMap API)\n• Equipment Proficiency: Total station, GPS, Dumpy Level\n\n\nWork Experience\nGeomatic Engineer, Oct 2024 – July 2025\nMac Partners Mining and Construction, Konongo\n• Accurately set out tower cranes, CIL tanks, and ball mills using Stonex Total Station and Hi-Target equipment, ensuring precise alignment with the approved site layout.\n• Established anchor bolt positions for structural components, enabling secure installation of bolts and nuts for critical equipment.\n• Verified excavation levels with a Bosch dumpy level to determine cut-and-fill requirements, optimizing earthwork planning and material usage.\n• Re-ordinated control pillars using Hi-Target GPS to maintain spatial accuracy and integrity of site control points\nAssistant Surveyor, Aug 2024 – Oct 2024\nPoint Engineering, Accra\n• Conducted comprehensive topographic and construction surveys using Trimble, Sokkia, and CHCNAV GPS systems to produce accurate topography maps and as-built documentation.\n• Precisely marked reinforcement layouts, column positions, and base points to ensure correct structural alignment during construction.\n• Successfully surveyed and profiled a 14 km road corridor using CHCNAV GPS, providing essential data for road design and engineering planning.\nGeomatic Engineer, May 2024 – Aug 2024\nSedzie Survey Engineering, Accra\n• Performed detailed road profiling at designated chainages to generate accurate sectional road designs and construction data.\n• Executed land demarcation using E-Survey software and CHCNAV GPS to delineate property parcels and link road alignments with precision.\n• Developed high-quality topographical maps from survey data collected on-site, supporting design and planning processes.\n• Survey Assistant (NationalServicePersonnel) AM Surveys Ltd, Haatso–Accra Oct 2022 – Sep 2023\n• Processed drone imagery using Agisoft Metashape to generate high-resolution orthophotos for accurate site representation.\n• Produced detailed topographic maps in AutoCAD Civil 3D to support design and construction planning.\n• Conducted precise parcel demarcation using E-Survey GPS, ensuring accurate land boundary delineation.\n\n\nLeadership Experience\nTraining Coordinator, Jan 2021 – Oct 2022\nUniversity of Mines and Technology, UMaT YouthMappers\n• Conducted GIS training sessions and led OpenStreetMap mapping campaigns to enhance community mapping skills and spatial data accuracy.\n• Trained team members on creating maps using GIS software, including QGIS and ArcMap, improving their technical proficiency in geospatial analysis.\n• Organized and facilitated drone training sessions for mappers, covering the complete workflow of drone data acquisition and processing.\n• Mapped areas around Tema to support COVID-19 PPE distribution efforts, improving location data for emergency response.\n• Contributed to streetlight and hydrant mapping projects through mobile and online OSM platforms, enhancing community infrastructure data.\nVice President, Jan 2021 – Nov 2021\nGeomatic Engineering Student Association (GESA)\n• Trained colleague students in using geospatial tools during tutorials organized by the department.\n• Obtained funds to run our administration together with the other executives.\n• Led the department in the registration of student members of the Ghana Institution of Surveyors.\n\n\nCertifications\n• Geospatial Python Bootcamp (12 Days) – Dec 2024\n• GIS for Climate Action (Esri MOOC) – Dec 2023\n• QGIS Training Program (21 Days) – Jul 2020\n• Drone Piloting and Data Processing, Soko Aerial Robotics – Jun 2019"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Peer-reviewed publications:\nDespite listing them on your resume, it may also be pertinent to create a seperate tab for publications and reports. As your career progresses, this list may become quite long, so be sure to organize things. You may want to point to ‘most recent’ publications, or categorize things by project/topic."
  },
  {
    "objectID": "content_development.html",
    "href": "content_development.html",
    "title": "Content & Deliverables",
    "section": "",
    "text": "Project Deliverable 1\nThis is a sample page where you can archive project deliverables."
  },
  {
    "objectID": "content.html",
    "href": "content.html",
    "title": "Content & Deliverables",
    "section": "",
    "text": "This is a sample page where you can archive project deliverables. Every header you use will correspond to a tab in the legend - shown on the right-hand side of your screen (“On this page”).\nIf you’ve produced any GIS layers for your 599 project, this may be a good place to share them as interactive maps through leaflet. Alternatively, you can upload high-res figures showing correlations, box-plots, etc. from your report here, and provide a brief overview of key project results. If you have written some useful functions, you may also want to share those here to demonstrate proficiency in particular coding languages or synergies between notable coding packages.\n\n\nSample leaflet - for detailed leaflet instructions, visit the FCOR 599 workshop archive page here.\n\n\n\n\n\n\n\n\n\nSample code snippet. Notice that you can provide a toggle to switch between coding languages - this is referred to as a ‘tabset’ in quarto. It is good practice to try and convert your R code to python, and vice-versa to demonstrate coding proficiency. For example, let’s showcase a function for calculating NDVI in R and Python.\n\nRPython\n\n\ncalc_ndvi &lt;- function(nir, red){\n  ndvi &lt;- (nir-red)/(nir+red)\n  return(ndvi)\n}\n(Assuming nir and red are terra rast objects)\n\n\ndef calc_ndvi(nir, red): \n  ndvi = (nir - red)/(nir + red)\n  return(ndvi)\n(Assuming nir and red are numpy arrays)\n\n\n\n\n\n\nYou can also provide a frame linking to external websites. For example, here is a Google Earth Engine application I developed - which I embedded in this webpage using the code below:\n\n\n&lt;iframe width=\"900\" height=\"700\"\nsrc=\"https://ee-melserramon.projects.earthengine.app/view/thermal-analysis-tool\"&gt;\n&lt;/iframe&gt;\n\nThe full-screen GEE application is available here in case you’re interested.\n(To use the GEE tool, navigate to any city you’d like, hit apply filters, and click anywhere on the map to retrieve a time-series of Landsat surface temperature observations for that point. Areas where the maximum temp exceeded 35 degrees Celsius in your date-range are highlighted in red.)"
  },
  {
    "objectID": "content.html#leaflet",
    "href": "content.html#leaflet",
    "title": "Content & Deliverables",
    "section": "",
    "text": "Sample leaflet - for detailed leaflet instructions, visit the FCOR 599 workshop archive page here."
  },
  {
    "objectID": "content.html#code-snippets",
    "href": "content.html#code-snippets",
    "title": "Content & Deliverables",
    "section": "",
    "text": "Sample code snippet. Notice that you can provide a toggle to switch between coding languages - this is referred to as a ‘tabset’ in quarto. It is good practice to try and convert your R code to python, and vice-versa to demonstrate coding proficiency. For example, let’s showcase a function for calculating NDVI in R and Python.\n\nRPython\n\n\ncalc_ndvi &lt;- function(nir, red){\n  ndvi &lt;- (nir-red)/(nir+red)\n  return(ndvi)\n}\n(Assuming nir and red are terra rast objects)\n\n\ndef calc_ndvi(nir, red): \n  ndvi = (nir - red)/(nir + red)\n  return(ndvi)\n(Assuming nir and red are numpy arrays)"
  },
  {
    "objectID": "content.html#external-links",
    "href": "content.html#external-links",
    "title": "Content & Deliverables",
    "section": "",
    "text": "You can also provide a frame linking to external websites. For example, here is a Google Earth Engine application I developed - which I embedded in this webpage using the code below:\n\n\n&lt;iframe width=\"900\" height=\"700\"\nsrc=\"https://ee-melserramon.projects.earthengine.app/view/thermal-analysis-tool\"&gt;\n&lt;/iframe&gt;\n\nThe full-screen GEE application is available here in case you’re interested.\n(To use the GEE tool, navigate to any city you’d like, hit apply filters, and click anywhere on the map to retrieve a time-series of Landsat surface temperature observations for that point. Areas where the maximum temp exceeded 35 degrees Celsius in your date-range are highlighted in red.)"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Capstone Project",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "projects.html#quarto",
    "href": "projects.html#quarto",
    "title": "Capstone Project",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "projects.html#running-code",
    "href": "projects.html#running-code",
    "title": "Capstone Project",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "projects.html#unmanned-aerial-vehicle-uav-multispectral-imagery-and-gis-based-approaches-for-vineyard-row-identification-and-segmentation-in-precision-viticulture",
    "href": "projects.html#unmanned-aerial-vehicle-uav-multispectral-imagery-and-gis-based-approaches-for-vineyard-row-identification-and-segmentation-in-precision-viticulture",
    "title": "Capstone Project",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Work_Experience.html",
    "href": "Work_Experience.html",
    "title": "Professional Experience",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Work_Experience.html#quarto",
    "href": "Work_Experience.html#quarto",
    "title": "Professional Experience",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Work_Experience.html#running-code",
    "href": "Work_Experience.html#running-code",
    "title": "Professional Experience",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "GIS_Technical Labs.html",
    "href": "GIS_Technical Labs.html",
    "title": "GIS & Technical Labs",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "GIS_Technical Labs.html#quarto",
    "href": "GIS_Technical Labs.html#quarto",
    "title": "GIS & Technical Labs",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "GIS_Technical Labs.html#running-code",
    "href": "GIS_Technical Labs.html#running-code",
    "title": "GIS & Technical Labs",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "work_experience.html",
    "href": "work_experience.html",
    "title": "Professional Experience",
    "section": "",
    "text": "At Mac Partners Mining and Construction, I played an active role in the construction of a gold processing plant at Northern Ashanti Mine (NAM). My responsibilities went beyond field surveying, including reading and interpreting engineering and site plans, coordinating with site engineers, and inspecting operations alongside mine surveyors to ensure alignment with design specifications. In the field, I set out tower cranes, CIL tanks, and ball mills using Stonex Total Station and Hi-Target GNSS, and established anchor bolt positions for major structural components to guarantee precise installation. I verified excavation levels using a Bosch dumpy level, optimizing cut-and-fill operations, and re-established survey control pillars to maintain the accuracy and integrity of site measurements. Through this combination of fieldwork, technical analysis, and collaboration, I contributed to the efficiency and safety of mining operations, ensuring construction activities adhered to approved plans while maintaining spatial accuracy across the site.\nTools & Technologies\nSouth total station, Stonex R35 total station,Sokkia 530r total station, Hi-Target V300 GNSS, Bosch dumpy level, AutoCad Civil 3D, MapInfo\nField Operations\n\n\n\n\n\n\n\n\n\nOffice plots"
  },
  {
    "objectID": "work_experience.html#quarto",
    "href": "work_experience.html#quarto",
    "title": "Professional Experience",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "work_experience.html#running-code",
    "href": "work_experience.html#running-code",
    "title": "Professional Experience",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "gis_technical_labs.html",
    "href": "gis_technical_labs.html",
    "title": "Technical Labs",
    "section": "",
    "text": "Landscape Connectivity Analysis for Species Movement\nThis project applied landscape ecology principles to evaluate structural and functional connectivity across a heterogeneous landscape using spatial analysis and network-based modeling in R. Using National Land Cover Data, landscape configuration was analyzed to understand how habitat distribution and matrix composition influence species movement and connectivity. Landscape metrics were used to quantify patch structure and spatial patterns, while network analysis techniques were employed to model potential movement pathways across the landscape. The project incorporated resistance-based modeling to simulate species-specific movement scenarios for ducks and spotted owls, accounting for differences in habitat preference and dispersal ability. Graphs and grains of connectivity models were developed across multiple thresholds to assess connectivity sensitivity at different spatial scales. The results highlight how landscape structure, habitat quality, and movement assumptions interact to shape ecological connectivity, demonstrating the value of connectivity modeling for conservation planning and landscape-scale environmental decision-making\nKey methods and Data\nLandscape ecology and connectivity theory, Structural and functional connectivity analysis, Network analysis, National Land Cover Data (NLCD)\nTools\nRstudio (landscapemetrics- Core area metric, Aggregation metric, Area and Edge metric)\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Fire Burn Severity and Post-Fire Vegetation Recovery Using Landsat Time-Series\nThe Prouton Lakes wildfire (2017) in the Alex Fraser Research Forest, BC, was examined for burn intensity and post-fire vegetation recovery using Landsat 8 surface reflectance time-series (2013-2021). Burn severity was assessed using the normalized burn ratio (NBR) and delta NBR (dNBR), which allowed impacted areas to be classified as unburned, low, medium, or high severity. Vegetation recovery was assessed by observing NDVI trends across burn severity classes for four years after the fire. Time-series composites, supervised classifiers, and statistical visualizations were used to investigate regional patterns of fire effects and vegetation recovery. This study highlights the use of remote sensing and spatial analysis in landscape ecology to aid in wildfire impact assessment and ecosystem management decisions.\nKey methods and Data\nRemote sensing analysis using Landsat 8 OLI Level-2 surface reflectance data, Vegetation and burn indices: NDVI, NBR, dNBR, Time-series processing and compositing for multiple years, Raster pre-processing: masking, cropping, and QA filtering\nTools\nRstudio (raster, terra, ggplot2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCartographic Modelling of Old-Growth Forests on Vancouver Island With Forest Inventories\nAlthough old-growth forests provide important ecological, biological, and wood resources, they are under threat from logging and human disturbances. This lab investigates the distribution of prospective old-growth stands on Vancouver Island, British Columbia, utilizing VRI data, land ownership layers, human disturbance data, and landscape units. Forest polygons were filtered to include managed crown forests, which were then divided into Seral Stages based on age and BEC zone, and human disturbances were adjusted. The percentage of old-growth forest was estimated for each Landscape Unit-BEC combination and compared to provincial targets. Cartographic modelling was used to depict the data, resulting in maps and tables that show locations that exceeded or fell short of the old-growth target. This workflow demonstrates how GIS and Python-based spatial analysis can help with forest management and conservation planning.\nKey methods and Data\nSubsetting VRI polygons to managed forests and extracting relevant attributes, Identifying crown forests using land ownership and human disturbance layers, Assigning Seral Stages (Early, Mid, Mature, Old) based on BEC zones and projected stand age; resetting stages in disturbed areas, Vegetation Resource Inventory 2024 (vancouver_island_vri), Generalized Forest Cover Ownership (vancouver_island_own)\nTools\nArcGIS Pro, Python, SQL\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning Techniques to Classify Deciduous or Coniferous Trees in the Petawawa Research Forest\nAccurate mapping of coniferous and deciduous tree species is essential for effective forest management, ecosystem monitoring, and long-term environmental planning. These forest types differ in growth patterns, ecological functions, and carbon storage potential, making their spatial delineation critical for decision-making. Advances in remote sensing and machine learning have created new opportunities to classify forest composition using spectral and structural information derived from satellite and aerial imagery. This project evaluated the performances of machine-learning classifiers (Random Forest (RF) and Support Vector Machine (SVM)), for distinguishing coniferous and deciduous trees within the Petawawa Research Forest. Both models were trained using the same set of predictor variables and reference data so that their performance could be compared fairly. Accuracy was assessed using classification metrics, including overall accuracy, precision, recall, and confusion matrices, along with model computation time. This direct comparison highlights how Random Forest and Support Vector Machine differ in both classification performance and efficiency, providing practical insight into their suitability for conifer and deciduous tree mapping in Canadian forest landscapes\nKey methods and Data\nSupervised machine learning classification of forest cover into coniferous and deciduous classes, Training and testing of two classifiers: Random Forest and Support Vector Machine, Comparison of model performance based on both classification accuracy and computation time, Airborne LiDAR\nTools\nArcgis Pro, Python, Scikit learn\n\n\n\n\n\n\n\n\n\n\n\nTerrain-Based Stream Network Delineation and Riparian Reserve Mapping in the Nahmint Watershed, British Columbia\nDigital terrain analysis and hydrological modelling were employed to delineate stream networks, determine stream order, and set riparian reserve buffers within the Nahmint watershed in British Columbia. A Digital Elevation Model (DEM) served as the foundation for modelling surface flow processes and deriving watershed characteristics through raster-based hydrological tools. The DEM was initially preprocessed to eliminate sinks and ensure continuous flow routing across the landscape. Flow direction and flow accumulation rasters were generated using the D8 algorithm, and a stream network was extracted using a specified accumulation threshold. Stream order was assigned using the Strahler classification method, and raster stream outputs were converted into vector features to facilitate further spatial analysis. Stream gradients were calculated from elevation differences along individual segments. Using these gradient values and observed channel characteristics, streams were classified according to provincial riparian management guidelines (S1–S6). Corresponding buffer distances for Riparian Reserve Zones and Riparian Management Zones were then applied based on stream class criteria. Watershed boundaries and contour lines were also derived to support terrain interpretation and contextual analysis. The results highlight the effectiveness of DEM-based hydrological modelling for systematic stream delineation and standardised riparian buffer mapping in forested environments.\nKey methods and Data\nWatershed delineation, DEM preprocessing, Stream network extraction using accumulation threshold, Contour generation, Digital Elevation Model (DEM) of the Nahmint watershed, Riparian Reserve and Management Zone buffer generation\nTools\nArcGIS Pro (Spatial Analyst Extension), QGIS for DEM access and export\n\n\n\n\n\n\n\n\n\n\n\nEstimating Forest Attributes Using Airborne LiDAR Metrics and Statistical Modeling Approaches\nAirborne LiDAR data were processed to derive terrain models, canopy-structure metrics, and wall-to-wall estimates of net stem volume for the Malcolm Knapp Research Forest (MKRF). Multiple. las tiles were managed using a LAScatalog workflow in R to enable efficient processing of the full dataset. Duplicate points were identified and removed before analysis. A Digital Elevation Model (DEM) was generated from ground-classified returns using TIN interpolation and subsequently used to normalize point cloud heights. A Canopy Height Model (CHM) was derived from normalized data to evaluate vegetation structure and confirm data quality. Circular forest plots were extracted from the normalized point cloud, and standard LiDAR metrics describing vegetation height, cover, and structural complexity were calculated for each plot using first returns above 2 m. These metrics were combined with field-measured net stem volume data to develop ordinary least squares regression models. A forward variable selection approach was applied to identify a simple and efficient predictive model. The final model was then applied across the entire study area by calculating pixel-level LiDAR metrics and generating a spatially continuous estimate of stem volume. Although the resulting model demonstrated moderate explanatory power, limitations associated with temporal mismatches between field and LiDAR data, variable-radius plot design, and limited structural variability among plots likely constrained predictive accuracy. The lab demonstrates the complete workflow for LiDAR-based Forest attribute estimation, from raw point cloud processing to spatial model application.\nKey methods and Data\nQuality control of point cloud data, Digital Elevation Model (DEM) generation using ground-classified returns, Height normalization of LiDAR point clouds using DEM subtraction, Wall-to-wall application of the selected model using pixel-based LiDAR metrics, Airborne LiDAR point cloud data (.las format) covering Malcolm Knapp Research Forest (MKRF), RGB aerial orthophoto (GeoTIFF format)\nTools\nRstudio (lidR, terra, tidyverse)\n\n\n\n\n\n\n\n\n\n\n\nSpatial Statistics to Enhance Classical Statistical Modelling of Spatial Data\nSpatial statistics enhances classical statistical modelling by explicitly accounting for location-dependent relationships in georeferenced data. Incorporating spatial autocorrelation and measurement scales allows classical methods such as simple linear regression, ANOVA, and multiple linear regression to be applied more effectively in spatial contexts. Geostatistical methods, including kriging and spatial interpolation, enable accurate prediction at unobserved locations and reconstruction of continuous surfaces, improving model reliability and reducing bias. Integrating spatial considerations uncovers patterns and dependencies that classical methods alone may overlook, providing a robust framework for exploratory analysis, inference, and prediction in complex spatial datasets.\nSkills Acquired\nManaged and analyzing georeferenced spatial data (geostatistical, areal, point patterns).\nAssessed and interpreting spatial autocorrelation.\nApplied SLR, ANOVA, and MLR in spatial contexts.\nPerformed data transformations and residual diagnostics for spatial models.\nConducted kriging and geostatistical interpolation for spatial prediction.\n\n\nEffective Communication and Multidisciplinary Knowledge for Sustainable Natural Resource\nEffective management of natural resources requires not only technical expertise but also the ability to integrate diverse knowledge systems and communicate insights clearly to stakeholders. Through this MGEM module, I engaged with sustainable resource management concepts, explored traditional and scientific knowledge integration, and applied professional communication strategies to convey complex information effectively. Emphasis was placed on understanding spatial variability, stakeholder perspectives, and interdisciplinary approaches to decision-making. The learning experience strengthened both analytical and communication competencies, preparing me to contribute meaningfully to sustainable natural resource initiatives.\nSkills Acquired\nIntegration of multidisciplinary knowledge for resource management.\nProfessional communication with diverse stakeholders.\nSpatial data interpretation and analysis.\nCollaborative problem-solving and decision-making."
  },
  {
    "objectID": "gis_technical_labs.html#quarto",
    "href": "gis_technical_labs.html#quarto",
    "title": "Technical Labs",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "gis_technical_labs.html#running-code",
    "href": "gis_technical_labs.html#running-code",
    "title": "Technical Labs",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "work_experience.html#mining-infrastructure-survey-and-site-coordination",
    "href": "work_experience.html#mining-infrastructure-survey-and-site-coordination",
    "title": "Professional Experience",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "work_experience.html#gold-processing-plant-refurbishment-construction-at-northern-ashanti-mine-nam",
    "href": "work_experience.html#gold-processing-plant-refurbishment-construction-at-northern-ashanti-mine-nam",
    "title": "Professional Experience",
    "section": "",
    "text": "At Mac Partners Mining and Construction, I played an active role in the construction of a gold processing plant at Northern Ashanti Mine (NAM). My responsibilities went beyond field surveying, including reading and interpreting engineering and site plans, coordinating with site engineers, and inspecting operations alongside mine surveyors to ensure alignment with design specifications. In the field, I set out tower cranes, CIL tanks, and ball mills using Stonex Total Station and Hi-Target GNSS, and established anchor bolt positions for major structural components to guarantee precise installation. I verified excavation levels using a Bosch dumpy level, optimizing cut-and-fill operations, and re-established survey control pillars to maintain the accuracy and integrity of site measurements. Through this combination of fieldwork, technical analysis, and collaboration, I contributed to the efficiency and safety of mining operations, ensuring construction activities adhered to approved plans while maintaining spatial accuracy across the site.\nTools & Technologies\nSouth total station, Stonex R35 total station,Sokkia 530r total station, Hi-Target V300 GNSS, Bosch dumpy level, AutoCad Civil 3D, MapInfo\nField Operations\n\n\n\n\n\n\n\n\n\nOffice plots"
  },
  {
    "objectID": "work_experience.html#topographic-and-construction-surveying-for-building-and-road-projects",
    "href": "work_experience.html#topographic-and-construction-surveying-for-building-and-road-projects",
    "title": "Professional Experience",
    "section": "Topographic and Construction Surveying for Building and Road Projects",
    "text": "Topographic and Construction Surveying for Building and Road Projects\nDuring my time at Point Engineering, I contributed to a variety of building, road, and irrigation farm surveying projects, working closely with the lead consultant surveyor and engaging in every step of the surveying process. On building projects, I carefully reviewed points set by contractor surveyors to ensure their accuracy and confirm that layouts matched the approved designs. For road networks and irrigation farm layouts, I collected precise topographic data using Trimble, Sokkia, and CHCNAV GNSS equipment, setting out reinforcement positions, column locations, base points, and road alignments while making sure all work met engineering specifications. I also surveyed and profiled a 14 km road corridor, generating longitudinal and cross-sectional data essential for design and planning. Beyond fieldwork, I collaborated closely with engineers and project managers to interpret survey results, resolve discrepancies, and produce detailed maps, reports, and visualizations that helped guide construction and infrastructure development.\nTools & Technologies\nTrimble total station, Trimble GPS, Sokkia 530r total station, CHC NAV GPS, AutoCad Civil 3D\nFieldworks"
  },
  {
    "objectID": "work_experience.html#drone-mapping-and-cadastraltopographical-surveys",
    "href": "work_experience.html#drone-mapping-and-cadastraltopographical-surveys",
    "title": "Professional Experience",
    "section": "Drone Mapping and Cadastral/Topographical Surveys",
    "text": "Drone Mapping and Cadastral/Topographical Surveys\nContributions at AM Surveys Ltd involved a range of survey and mapping projects that integrated drone-based imagery, topographical surveys, cadastral work, and GIS analysis. Operating the Delta Quad drone, I collected high-resolution aerial imagery to monitor waterbody conditions and mapped aquatic vegetation using Picterra software, generating actionable data for environmental assessments. I also performed cadastral and topographical surveys, creating accurate plots in AutoCAD and conducting spatial analysis in QGIS to support land management and client deliverables. Beyond these projects, I assisted with general mapping and field data collection, ensuring survey outputs were precise, well-documented, and reliable.\nTools and Technologies\nDelta Quad drone, Picterra software, AutoCAD Civil 3D, QGIS, MapInfo, , Hi-Target GPS, E-Survey GPS\nFieldworks"
  },
  {
    "objectID": "work_experience.html#topographic-construction-surveying-for-building-and-road-projects",
    "href": "work_experience.html#topographic-construction-surveying-for-building-and-road-projects",
    "title": "Professional Experience",
    "section": "Topographic & Construction Surveying for Building and Road Projects",
    "text": "Topographic & Construction Surveying for Building and Road Projects\nDuring my time at Point Engineering, I contributed to a variety of building, road, and irrigation farm surveying projects, working closely with the lead consultant surveyor and engaging in every step of the surveying process. On building projects, I carefully reviewed points set by contractor surveyors to ensure their accuracy and confirm that layouts matched the approved designs. For road networks and irrigation farm layouts, I collected precise topographic data using Trimble, Sokkia, and CHCNAV GNSS equipment, setting out reinforcement positions, column locations, base points, and road alignments while making sure all work met engineering specifications. I also surveyed and profiled a 14 km road corridor, generating longitudinal and cross-sectional data essential for design and planning. Beyond fieldwork, I collaborated closely with engineers and project managers to interpret survey results, resolve discrepancies, and produce detailed maps, reports, and visualizations that helped guide construction and infrastructure development.\nTools & Technologies\nTrimble total station, Trimble GPS, Sokkia 530r total station, CHC NAV GPS, AutoCad Civil 3D\nFieldworks"
  },
  {
    "objectID": "work_experience.html#drone-mapping-cadastraltopographical-surveys",
    "href": "work_experience.html#drone-mapping-cadastraltopographical-surveys",
    "title": "Professional Experience",
    "section": "Drone Mapping & Cadastral/Topographical Surveys",
    "text": "Drone Mapping & Cadastral/Topographical Surveys\nContributions at AM Surveys Ltd involved a range of survey and mapping projects that integrated drone-based imagery, topographical surveys, cadastral work, and GIS analysis. Operating the Delta Quad drone, I collected high-resolution aerial imagery to monitor waterbody conditions and mapped aquatic vegetation using Picterra software, generating actionable data for environmental assessments. I also performed cadastral and topographical surveys, creating accurate plots in AutoCAD and conducting spatial analysis in QGIS to support land management and client deliverables. Beyond these projects, I assisted with general mapping and field data collection, ensuring survey outputs were precise, well-documented, and reliable.\nTools and Technologies\nDelta Quad drone, Picterra software, AutoCAD Civil 3D, QGIS, MapInfo, , Hi-Target GPS, E-Survey GPS\nFieldworks"
  },
  {
    "objectID": "projects.html#crime-analysis-and-assessment-using-data-mining-techniques",
    "href": "projects.html#crime-analysis-and-assessment-using-data-mining-techniques",
    "title": "Capstone Project",
    "section": "Crime Analysis and Assessment using Data Mining Techniques",
    "text": "Crime Analysis and Assessment using Data Mining Techniques\nCrimes are actions committed in violation of the law. These crime activities have increased over the years due to high standards of living, unemployment, etc. which need to be curbed to ensure a safe society. Law enforcement agencies can effectively curb the canker by analysing previous crimes to understand the pattern of occurrence of these crimes to gather intelligence to tackle the situation effectively. Initially, law enforcement agencies carry out analysis of crimes on papers or use analogue techniques which is time consuming and tedious as one may have to deal with large paper sizes. In recent years, digital techniques such as the use of artificial intelligence which have proven to be better than traditional techniques are been used to carry out various analyses of crime data. This study has employed digital techniques such as data mining to analyse crime data in Chicago. The techniques used were the Random Forest classifier and Decision tree which were used to analyse and classify crimes into low, medium and high crimes. In comparison to the Decision tree, the Random Forest classifier outperformed it. Accuracy, precision, and recall for the Random Forest classifier are, respectively, 77%, 77%, and 77%. However, the decision trees’ values for accuracy, precision, and recall are 75%, 75%, and 76%, respectively. Additionally, a map of crime hotspots was created using an analysis of Chicago’s historical crime data to show security agencies where crimes are most likely to occur\nKey methods and Data\nData mining techniques (decision trees and random forest classifiers) for crime prediction and analysis, Spatial clustering, Secondary data obtained from Chicago Police Department Statistics Portal\nTools\nOpenstreetmap, Google colab"
  }
]