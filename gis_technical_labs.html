<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Technical Labs – Kelvin Boateng E-Portfolio</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-ffa9a6279353761231ec249df0a7fdd3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Kelvin Boateng E-Portfolio</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./resume.html"> 
<span class="menu-text">Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./projects.html"> 
<span class="menu-text">Academic Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./gis_technical_labs.html" aria-current="page"> 
<span class="menu-text">GIS &amp; Technical Work</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./work_experience.html"> 
<span class="menu-text">Professional Experience</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#landscape-connectivity-analysis-for-species-movement" id="toc-landscape-connectivity-analysis-for-species-movement" class="nav-link active" data-scroll-target="#landscape-connectivity-analysis-for-species-movement">Landscape Connectivity Analysis for Species Movement</a></li>
  <li><a href="#analysis-of-fire-burn-severity-and-post-fire-vegetation-recovery-using-landsat-time-series" id="toc-analysis-of-fire-burn-severity-and-post-fire-vegetation-recovery-using-landsat-time-series" class="nav-link" data-scroll-target="#analysis-of-fire-burn-severity-and-post-fire-vegetation-recovery-using-landsat-time-series">Analysis of Fire Burn Severity and Post-Fire Vegetation Recovery Using Landsat Time-Series</a></li>
  <li><a href="#cartographic-modelling-of-old-growth-forests-on-vancouver-island-with-forest-inventories" id="toc-cartographic-modelling-of-old-growth-forests-on-vancouver-island-with-forest-inventories" class="nav-link" data-scroll-target="#cartographic-modelling-of-old-growth-forests-on-vancouver-island-with-forest-inventories">Cartographic Modelling of Old-Growth Forests on Vancouver Island With Forest Inventories</a></li>
  <li><a href="#machine-learning-techniques-to-classify-deciduous-or-coniferous-trees-in-the-petawawa-research-forest" id="toc-machine-learning-techniques-to-classify-deciduous-or-coniferous-trees-in-the-petawawa-research-forest" class="nav-link" data-scroll-target="#machine-learning-techniques-to-classify-deciduous-or-coniferous-trees-in-the-petawawa-research-forest">Machine Learning Techniques to Classify Deciduous or Coniferous Trees in the Petawawa Research Forest</a></li>
  <li><a href="#terrain-based-stream-network-delineation-and-riparian-reserve-mapping-in-the-nahmint-watershed-british-columbia" id="toc-terrain-based-stream-network-delineation-and-riparian-reserve-mapping-in-the-nahmint-watershed-british-columbia" class="nav-link" data-scroll-target="#terrain-based-stream-network-delineation-and-riparian-reserve-mapping-in-the-nahmint-watershed-british-columbia">Terrain-Based Stream Network Delineation and Riparian Reserve Mapping in the Nahmint Watershed, British Columbia</a></li>
  <li><a href="#estimating-forest-attributes-using-airborne-lidar-metrics-and-statistical-modeling-approaches" id="toc-estimating-forest-attributes-using-airborne-lidar-metrics-and-statistical-modeling-approaches" class="nav-link" data-scroll-target="#estimating-forest-attributes-using-airborne-lidar-metrics-and-statistical-modeling-approaches">Estimating Forest Attributes Using Airborne LiDAR Metrics and Statistical Modeling Approaches</a></li>
  <li><a href="#spatial-statistics-to-enhance-classical-statistical-modelling-of-spatial-data" id="toc-spatial-statistics-to-enhance-classical-statistical-modelling-of-spatial-data" class="nav-link" data-scroll-target="#spatial-statistics-to-enhance-classical-statistical-modelling-of-spatial-data">Spatial Statistics to Enhance Classical Statistical Modelling of Spatial Data</a></li>
  <li><a href="#effective-communication-and-multidisciplinary-knowledge-for-sustainable-natural-resource" id="toc-effective-communication-and-multidisciplinary-knowledge-for-sustainable-natural-resource" class="nav-link" data-scroll-target="#effective-communication-and-multidisciplinary-knowledge-for-sustainable-natural-resource">Effective Communication and Multidisciplinary Knowledge for Sustainable Natural Resource</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Technical Labs</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="landscape-connectivity-analysis-for-species-movement" class="level1">
<h1>Landscape Connectivity Analysis for Species Movement</h1>
<p>This project applied landscape ecology principles to evaluate structural and functional connectivity across a heterogeneous landscape using spatial analysis and network-based modeling in R. Using National Land Cover Data, landscape configuration was analyzed to understand how habitat distribution and matrix composition influence species movement and connectivity. Landscape metrics were used to quantify patch structure and spatial patterns, while network analysis techniques were employed to model potential movement pathways across the landscape. The project incorporated resistance-based modeling to simulate species-specific movement scenarios for ducks and spotted owls, accounting for differences in habitat preference and dispersal ability. Graphs and grains of connectivity models were developed across multiple thresholds to assess connectivity sensitivity at different spatial scales. The results highlight how landscape structure, habitat quality, and movement assumptions interact to shape ecological connectivity, demonstrating the value of connectivity modeling for conservation planning and landscape-scale environmental decision-making</p>
<p><strong>Key methods and Data</strong></p>
<p>Landscape ecology and connectivity theory, Structural and functional connectivity analysis, Network analysis, National Land Cover Data (NLCD)</p>
<p><strong>Tools</strong></p>
<p>Rstudio (landscapemetrics- Core area metric, Aggregation metric, Area and Edge metric)</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="gis_technical_labs_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="1344"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="analysis-of-fire-burn-severity-and-post-fire-vegetation-recovery-using-landsat-time-series" class="level1">
<h1>Analysis of Fire Burn Severity and Post-Fire Vegetation Recovery Using Landsat Time-Series</h1>
<p>The Prouton Lakes wildfire (2017) in the Alex Fraser Research Forest, BC, was examined for burn intensity and post-fire vegetation recovery using Landsat 8 surface reflectance time-series (2013-2021). Burn severity was assessed using the normalized burn ratio (NBR) and delta NBR (dNBR), which allowed impacted areas to be classified as unburned, low, medium, or high severity. Vegetation recovery was assessed by observing NDVI trends across burn severity classes for four years after the fire. Time-series composites, supervised classifiers, and statistical visualizations were used to investigate regional patterns of fire effects and vegetation recovery. This study highlights the use of remote sensing and spatial analysis in landscape ecology to aid in wildfire impact assessment and ecosystem management decisions.</p>
<p><strong>Key methods and Data</strong></p>
<p>Remote sensing analysis using Landsat 8 OLI Level-2 surface reflectance data, Vegetation and burn indices: NDVI, NBR, dNBR, Time-series processing and compositing for multiple years, Raster pre-processing: masking, cropping, and QA filtering</p>
<p><strong>Tools</strong></p>
<p>Rstudio (raster, terra, ggplot2)</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="gis_technical_labs_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="1344"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="gis_technical_labs_files/figure-html/unnamed-chunk-2-2.png" class="img-fluid figure-img" width="1344"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="cartographic-modelling-of-old-growth-forests-on-vancouver-island-with-forest-inventories" class="level1">
<h1>Cartographic Modelling of Old-Growth Forests on Vancouver Island With Forest Inventories</h1>
<p>Although old-growth forests provide important ecological, biological, and wood resources, they are under threat from logging and human disturbances. This lab investigates the distribution of prospective old-growth stands on Vancouver Island, British Columbia, utilizing VRI data, land ownership layers, human disturbance data, and landscape units. Forest polygons were filtered to include managed crown forests, which were then divided into Seral Stages based on age and BEC zone, and human disturbances were adjusted. The percentage of old-growth forest was estimated for each Landscape Unit-BEC combination and compared to provincial targets. Cartographic modelling was used to depict the data, resulting in maps and tables that show locations that exceeded or fell short of the old-growth target. This workflow demonstrates how GIS and Python-based spatial analysis can help with forest management and conservation planning.</p>
<p><strong>Key methods and Data</strong></p>
<p>Subsetting VRI polygons to managed forests and extracting relevant attributes, Identifying crown forests using land ownership and human disturbance layers, Assigning Seral Stages (Early, Mid, Mature, Old) based on BEC zones and projected stand age; resetting stages in disturbed areas, Vegetation Resource Inventory 2024 (vancouver_island_vri), Generalized Forest Cover Ownership (vancouver_island_own)</p>
<p><strong>Tools</strong></p>
<p>ArcGIS Pro, Python, SQL</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="gis_technical_labs_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="machine-learning-techniques-to-classify-deciduous-or-coniferous-trees-in-the-petawawa-research-forest" class="level1">
<h1>Machine Learning Techniques to Classify Deciduous or Coniferous Trees in the Petawawa Research Forest</h1>
<p>Accurate mapping of coniferous and deciduous tree species is essential for effective forest management, ecosystem monitoring, and long-term environmental planning. These forest types differ in growth patterns, ecological functions, and carbon storage potential, making their spatial delineation critical for decision-making. Advances in remote sensing and machine learning have created new opportunities to classify forest composition using spectral and structural information derived from satellite and aerial imagery. This project evaluated the performances of machine-learning classifiers (Random Forest (RF) and Support Vector Machine (SVM)), for distinguishing coniferous and deciduous trees within the Petawawa Research Forest. Both models were trained using the same set of predictor variables and reference data so that their performance could be compared fairly. Accuracy was assessed using classification metrics, including overall accuracy, precision, recall, and confusion matrices, along with model computation time. This direct comparison highlights how Random Forest and Support Vector Machine differ in both classification performance and efficiency, providing practical insight into their suitability for conifer and deciduous tree mapping in Canadian forest landscapes</p>
<p><strong>Key methods and Data</strong></p>
<p>Supervised machine learning classification of forest cover into coniferous and deciduous classes, Training and testing of two classifiers: Random Forest and Support Vector Machine, Comparison of model performance based on both classification accuracy and computation time, Airborne LiDAR</p>
<p><strong>Tools</strong></p>
<p>Arcgis Pro, Python, Scikit learn</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="gis_technical_labs_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="terrain-based-stream-network-delineation-and-riparian-reserve-mapping-in-the-nahmint-watershed-british-columbia" class="level1">
<h1>Terrain-Based Stream Network Delineation and Riparian Reserve Mapping in the Nahmint Watershed, British Columbia</h1>
<p>Digital terrain analysis and hydrological modelling were employed to delineate stream networks, determine stream order, and set riparian reserve buffers within the Nahmint watershed in British Columbia. A Digital Elevation Model (DEM) served as the foundation for modelling surface flow processes and deriving watershed characteristics through raster-based hydrological tools. The DEM was initially preprocessed to eliminate sinks and ensure continuous flow routing across the landscape. Flow direction and flow accumulation rasters were generated using the D8 algorithm, and a stream network was extracted using a specified accumulation threshold. Stream order was assigned using the Strahler classification method, and raster stream outputs were converted into vector features to facilitate further spatial analysis. Stream gradients were calculated from elevation differences along individual segments. Using these gradient values and observed channel characteristics, streams were classified according to provincial riparian management guidelines (S1–S6). Corresponding buffer distances for Riparian Reserve Zones and Riparian Management Zones were then applied based on stream class criteria. Watershed boundaries and contour lines were also derived to support terrain interpretation and contextual analysis. The results highlight the effectiveness of DEM-based hydrological modelling for systematic stream delineation and standardised riparian buffer mapping in forested environments.</p>
<p><strong>Key methods and Data</strong></p>
<p>Watershed delineation, DEM preprocessing, Stream network extraction using accumulation threshold, Contour generation, Digital Elevation Model (DEM) of the Nahmint watershed, Riparian Reserve and Management Zone buffer generation</p>
<p><strong>Tools</strong></p>
<p>ArcGIS Pro (Spatial Analyst Extension), QGIS for DEM access and export</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="gis_technical_labs_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="estimating-forest-attributes-using-airborne-lidar-metrics-and-statistical-modeling-approaches" class="level1">
<h1>Estimating Forest Attributes Using Airborne LiDAR Metrics and Statistical Modeling Approaches</h1>
<p>Airborne LiDAR data were processed to derive terrain models, canopy-structure metrics, and wall-to-wall estimates of net stem volume for the Malcolm Knapp Research Forest (MKRF). Multiple. las tiles were managed using a LAScatalog workflow in R to enable efficient processing of the full dataset. Duplicate points were identified and removed before analysis. A Digital Elevation Model (DEM) was generated from ground-classified returns using TIN interpolation and subsequently used to normalize point cloud heights. A Canopy Height Model (CHM) was derived from normalized data to evaluate vegetation structure and confirm data quality. Circular forest plots were extracted from the normalized point cloud, and standard LiDAR metrics describing vegetation height, cover, and structural complexity were calculated for each plot using first returns above 2 m. These metrics were combined with field-measured net stem volume data to develop ordinary least squares regression models. A forward variable selection approach was applied to identify a simple and efficient predictive model. The final model was then applied across the entire study area by calculating pixel-level LiDAR metrics and generating a spatially continuous estimate of stem volume. Although the resulting model demonstrated moderate explanatory power, limitations associated with temporal mismatches between field and LiDAR data, variable-radius plot design, and limited structural variability among plots likely constrained predictive accuracy. The lab demonstrates the complete workflow for LiDAR-based Forest attribute estimation, from raw point cloud processing to spatial model application.</p>
<p><strong>Key methods and Data</strong></p>
<p>Quality control of point cloud data, Digital Elevation Model (DEM) generation using ground-classified returns, Height normalization of LiDAR point clouds using DEM subtraction, Wall-to-wall application of the selected model using pixel-based LiDAR metrics, Airborne LiDAR point cloud data (.las format) covering Malcolm Knapp Research Forest (MKRF), RGB aerial orthophoto (GeoTIFF format)</p>
<p><strong>Tools</strong></p>
<p>Rstudio (lidR, terra, tidyverse)</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="gis_technical_labs_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="1344"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="spatial-statistics-to-enhance-classical-statistical-modelling-of-spatial-data" class="level1">
<h1>Spatial Statistics to Enhance Classical Statistical Modelling of Spatial Data</h1>
<p>Spatial statistics enhances classical statistical modelling by explicitly accounting for location-dependent relationships in georeferenced data. Incorporating spatial autocorrelation and measurement scales allows classical methods such as simple linear regression, ANOVA, and multiple linear regression to be applied more effectively in spatial contexts. Geostatistical methods, including kriging and spatial interpolation, enable accurate prediction at unobserved locations and reconstruction of continuous surfaces, improving model reliability and reducing bias. Integrating spatial considerations uncovers patterns and dependencies that classical methods alone may overlook, providing a robust framework for exploratory analysis, inference, and prediction in complex spatial datasets.</p>
<p><strong>Skills Acquired</strong></p>
<p>Managed and analyzing georeferenced spatial data (geostatistical, areal, point patterns).</p>
<p>Assessed and interpreting spatial autocorrelation.</p>
<p>Applied SLR, ANOVA, and MLR in spatial contexts.</p>
<p>Performed data transformations and residual diagnostics for spatial models.</p>
<p>Conducted kriging and geostatistical interpolation for spatial prediction.</p>
</section>
<section id="effective-communication-and-multidisciplinary-knowledge-for-sustainable-natural-resource" class="level1">
<h1>Effective Communication and Multidisciplinary Knowledge for Sustainable Natural Resource</h1>
<p>Effective management of natural resources requires not only technical expertise but also the ability to integrate diverse knowledge systems and communicate insights clearly to stakeholders. Through this MGEM module, I engaged with sustainable resource management concepts, explored traditional and scientific knowledge integration, and applied professional communication strategies to convey complex information effectively. Emphasis was placed on understanding spatial variability, stakeholder perspectives, and interdisciplinary approaches to decision-making. The learning experience strengthened both analytical and communication competencies, preparing me to contribute meaningfully to sustainable natural resource initiatives.</p>
<p><strong>Skills Acquired</strong></p>
<p>Integration of multidisciplinary knowledge for resource management.</p>
<p>Professional communication with diverse stakeholders.</p>
<p>Spatial data interpretation and analysis.</p>
<p>Collaborative problem-solving and decision-making.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>